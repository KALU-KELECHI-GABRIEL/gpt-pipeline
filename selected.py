import openai
import json




# file_acm = "./acm.json"
# file_ieee = "./ieee.json"

# Load the JSON file
# with open('./ieee.json', 'r') as file_IEEE:
#     data_ieee = json.load(file_IEEE)
#     data_acm = json.load(file_acm)
# # Load the JSON file
with open('./modified_data_acm.json', 'r') as file_acm, open('./modified_data_ieee.json', 'r') as file_ieee:
    data_ieee = json.load(file_ieee)
    data_acm = json.load(file_acm)

# client = OpenAI(
#   api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted
# )

def generate_review(abstract):
    """
    Generates a review for a given abstract using GPT-3.
    :param abstract: The abstract text.
    :return: Review generated by the language model.
    """
    prompt = f"Abstract: {abstract}\n\nDoes this abstract indicate that the paper reports on a (type of) Machine learning vulnerability or machine learning defect or machine learning bug? Indicate with just a YES or NO:"
    response = openai.Completion.create(
        engine="gpt-3.5-turbo",
        prompt=prompt,
        max_tokens=500,  # Adjust as needed
        temperature=0.7,  # Higher values make output more random
        stop=["\n"],  # Stop at the end of the review
    )
    return response



def chat_with_gpt(prompt):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",  # Adjust the model as necessary
        messages=[
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message["content"].strip()

# if __name__ == "__main__":
#     while True:
#         user_input = input("You: ").lower()
#         if user_input in ["quit", "exit", "bye"]:
#             break
#         response = chat_with_gpt(user_input)
#         print("Chatbot:", response)
        
# Example usage
# abstract_text = """
# Log data analysis is an essential task when it comes to 
# understanding a computer's or a network's system behavior, 
# and enables security analysis, fault diagnosis, performance analysis, or 
# intrusion detection. An established technique for log analysis is log line clustering, 
# which allows to group similar events and to detect outliers, malicious clusters or changes in system behavior. 
# However, log line clusters usually lack meaningful descriptions that are required to understand the information 
# provided by log lines within a cluster. Template generators allow to produce such descriptions in form of patterns 
# that match all log lines within a cluster and therefore describe the common features 
# of the lines. Current approaches only allow generation of token-based (e.g., space-separated words) 
# templates, which are often inaccurate, because they do not recognize words that 
# can be spelled differently as similar and require further information on the 
# structure and syntax of the data, such as predefined delimiters. Consequently, 
# novel character-based template generators are required that provide robust templates for any type of computer log data, 
# which can be applied in security information and event management (SIEM) solutions, 
# for continuous auditing, quality inspection and control. In this paper, 
# we propose a novel approach for computing character-based templates, 
# which combines comparison-based methods and heuristics. To achieve this goal, 
# we solve the problem of efficiently calculating a 
# multi-line alignment for a group of log lines and compute an accurate approximation of the optimal character-based template, 
# while reducing the runtime from O(n^m) to O(mn^2). 
# We demonstrate the accuracy of our approach in a detailed evaluation, 
# applying a newly introduced measure for accuracy, the Sim-Score, 
# which can be computed independently from a ground truth, and the established F-Score. 
# Furthermore, we assess the robustness of the algorithm and the influence of different 
# log data properties on the quality of the resulting templates."""

# prompt_message = f"Abstract: {abstract_text}\n\nDoes this abstract indicate that the paper reports on a (type of) Machine learning vulnerability or machine learning defect or machine learning bug? Indicate with just a YES or NO:"

# review = chat_with_gpt(prompt_message)
# print("Generated Review:")
# print(review)


acm_papers = {'yes': 0, 'no': 0}
ieee_papers = {'yes': 0, 'no': 0}
acm_final = []
ieee_final = []

# Loop through each entry and add a new field 'country' to each entry
for entry in data_acm:
    # prompt_message = f"Abstract: {entry['Abstract']}\n\nDoes this abstract indicate that the paper reports on a (type of) Machine learning vulnerability or machine learning defect or machine learning bug? Indicate with just a YES or NO:"
    # verdict = chat_with_gpt(prompt_message)
    # entry['verdict'] = verdict
    if entry['verdict']  == "YES":
        acm_final.append(entry)
        acm_papers["yes"] += 1
    else:
        acm_papers["no"] += 1
    
for entry in data_ieee:
    # prompt_message = f"Abstract: {entry['Abstract']}\n\nDoes this abstract indicate that the paper reports on a (type of) Machine learning vulnerability or machine learning defect or machine learning bug? Indicate with just a YES or NO:"
    # verdict = chat_with_gpt(prompt_message)
    if entry['verdict']  == "YES":
        ieee_final.append(entry)
        ieee_papers["yes"] += 1
    else:
        ieee_papers["no"] += 1
    
# Print the modified data
# print(json.dumps(data_ieee, indent=2))
# print(json.dumps(data_acm, indent=2))

# You can also write the modified data back to a file if needed
with open('data_ieee_final.json', 'w') as file:
    json.dump(ieee_final, file, indent=2)

with open('data_acm_final.json', 'w') as file:
    json.dump(acm_final, file, indent=2)